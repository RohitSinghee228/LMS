version: '3.8'

services:
  lms_server:
    build:
      context: .
      dockerfile: Dockerfile.server
    ports:
      - "50051:50051"
    depends_on:
      - mongo
    environment:
      - MONGO_URI=mongodb://mongo:27017/lms_db
      - OLLAMA_URI=http://ollama:11434 
    container_name: lms_server
    volumes:
      - server_data:/app/documents


  lms_client:
    build:
      context: .
      dockerfile: Dockerfile.client
    ports:
      - "5000:5000"
    depends_on:
      - lms_server
    container_name: lms_client

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"
    container_name: mongo
    volumes:
      - mongo_data:/data/db
  
  ollama:
    build:
      context: .
      dockerfile: Dockerfile.llm  # Use the latest Ollama image
    container_name: ollama
    # volumes:
    #   - ollama_data:/root/.ollama  # Persistent storage for Ollama models
    ports:
      - "11434:11434"  # Expose Ollama's API port
    # entrypoint: ["/bin/bash", "-c"]  # Run bash as entrypoint
    # command: ["ollama serve & ollama create tutor -f /root/.ollama/Modelfile && ollama run tutor"]  # Run the ollama command


volumes:
  mongo_data:
  server_data:
